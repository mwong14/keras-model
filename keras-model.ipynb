{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as plt\n",
    "import os, re, shutil, string\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dropout\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.16.1'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'train/animals.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>animal/not</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chameleon</td>\n",
       "      <td>animal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Suede</td>\n",
       "      <td>not animal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gazelle</td>\n",
       "      <td>animal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Soil</td>\n",
       "      <td>not animal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nitrogen</td>\n",
       "      <td>not animal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>Desk</td>\n",
       "      <td>not animal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>Shale</td>\n",
       "      <td>not animal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>Crow</td>\n",
       "      <td>animal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>Cockroach</td>\n",
       "      <td>animal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>cobalt</td>\n",
       "      <td>not animal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>215 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          name  animal/not\n",
       "0    Chameleon      animal\n",
       "1        Suede  not animal\n",
       "2      Gazelle      animal\n",
       "3         Soil  not animal\n",
       "4     Nitrogen  not animal\n",
       "..         ...         ...\n",
       "210       Desk  not animal\n",
       "211      Shale  not animal\n",
       "212       Crow      animal\n",
       "213  Cockroach      animal\n",
       "214     cobalt  not animal\n",
       "\n",
       "[215 rows x 2 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_train = pd.read_csv('train/animals.csv')\n",
    "words_train = words_train.sample(frac=1, random_state=60).reset_index(drop=True)\n",
    "words_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['name', 'animal/not'], dtype='object')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_feature = words_train.copy()\n",
    "words_feature.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_label = words_feature.pop('animal/not')\n",
    "word_label = word_label.str.lstrip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chameleon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>suede</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gazelle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>soil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nitrogen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>desk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>shale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>crow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>cockroach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>cobalt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>215 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          name\n",
       "0    chameleon\n",
       "1        suede\n",
       "2      gazelle\n",
       "3         soil\n",
       "4     nitrogen\n",
       "..         ...\n",
       "210       desk\n",
       "211      shale\n",
       "212       crow\n",
       "213  cockroach\n",
       "214     cobalt\n",
       "\n",
       "[215 rows x 1 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_feature = words_feature.map(lambda s: s.lower())\n",
    "words_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.legacy.preprocessing.text.Tokenizer at 0x17a620f9490>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(words_feature['name'])\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['animal', 'not animal'], dtype=object)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_label_encoded = pd.get_dummies(word_label)\n",
    "words_label_encoded = words_label_encoded.astype(int)\n",
    "del words_label_encoded['not animal']\n",
    "words_label_encoded_np = words_label_encoded.values\n",
    "words_label_encoded_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sequences = tokenizer.texts_to_sequences(words_feature['name'])\n",
    "sequences_padded = pad_sequences(sequences)\n",
    "sequences_padded = np.array(sequences_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6],\n",
       "       [  7],\n",
       "       [  8],\n",
       "       [  9],\n",
       "       [ 10],\n",
       "       [ 11],\n",
       "       [ 12],\n",
       "       [ 13],\n",
       "       [ 14],\n",
       "       [ 15],\n",
       "       [ 16],\n",
       "       [ 17],\n",
       "       [ 18],\n",
       "       [ 19],\n",
       "       [ 20],\n",
       "       [ 21],\n",
       "       [ 22],\n",
       "       [ 23],\n",
       "       [ 24],\n",
       "       [ 25],\n",
       "       [  1],\n",
       "       [ 26],\n",
       "       [ 27],\n",
       "       [ 28],\n",
       "       [ 29],\n",
       "       [ 30],\n",
       "       [ 31],\n",
       "       [ 32],\n",
       "       [ 33],\n",
       "       [ 34],\n",
       "       [ 35],\n",
       "       [ 36],\n",
       "       [ 37],\n",
       "       [ 38],\n",
       "       [  2],\n",
       "       [ 39],\n",
       "       [ 40],\n",
       "       [ 41],\n",
       "       [ 42],\n",
       "       [  1],\n",
       "       [ 43],\n",
       "       [  3],\n",
       "       [ 44],\n",
       "       [ 45],\n",
       "       [ 46],\n",
       "       [ 47],\n",
       "       [ 48],\n",
       "       [ 49],\n",
       "       [ 50],\n",
       "       [ 51],\n",
       "       [ 52],\n",
       "       [ 53],\n",
       "       [ 54],\n",
       "       [ 55],\n",
       "       [ 56],\n",
       "       [ 57],\n",
       "       [ 58],\n",
       "       [  2],\n",
       "       [ 59],\n",
       "       [ 60],\n",
       "       [ 61],\n",
       "       [ 62],\n",
       "       [ 63],\n",
       "       [ 64],\n",
       "       [ 65],\n",
       "       [ 66],\n",
       "       [  4],\n",
       "       [ 67],\n",
       "       [ 68],\n",
       "       [ 69],\n",
       "       [  3],\n",
       "       [ 70],\n",
       "       [ 71],\n",
       "       [ 72],\n",
       "       [ 73],\n",
       "       [  5],\n",
       "       [ 74],\n",
       "       [ 75],\n",
       "       [ 76],\n",
       "       [ 77],\n",
       "       [ 78],\n",
       "       [ 79],\n",
       "       [ 80],\n",
       "       [ 81],\n",
       "       [ 82],\n",
       "       [ 83],\n",
       "       [ 84],\n",
       "       [ 85],\n",
       "       [ 86],\n",
       "       [ 87],\n",
       "       [ 88],\n",
       "       [ 89],\n",
       "       [ 90],\n",
       "       [ 91],\n",
       "       [ 92],\n",
       "       [ 93],\n",
       "       [ 94],\n",
       "       [ 95],\n",
       "       [ 96],\n",
       "       [ 97],\n",
       "       [ 98],\n",
       "       [ 99],\n",
       "       [100],\n",
       "       [101],\n",
       "       [102],\n",
       "       [103],\n",
       "       [104],\n",
       "       [105],\n",
       "       [106],\n",
       "       [107],\n",
       "       [108],\n",
       "       [109],\n",
       "       [110],\n",
       "       [111],\n",
       "       [112],\n",
       "       [113],\n",
       "       [114],\n",
       "       [115],\n",
       "       [116],\n",
       "       [117],\n",
       "       [118],\n",
       "       [119],\n",
       "       [120],\n",
       "       [121],\n",
       "       [122],\n",
       "       [123],\n",
       "       [124],\n",
       "       [125],\n",
       "       [126],\n",
       "       [127],\n",
       "       [128],\n",
       "       [129],\n",
       "       [130],\n",
       "       [131],\n",
       "       [132],\n",
       "       [133],\n",
       "       [134],\n",
       "       [135],\n",
       "       [136],\n",
       "       [137],\n",
       "       [138],\n",
       "       [139],\n",
       "       [140],\n",
       "       [141],\n",
       "       [142],\n",
       "       [143],\n",
       "       [144],\n",
       "       [145],\n",
       "       [146],\n",
       "       [147],\n",
       "       [148],\n",
       "       [149],\n",
       "       [150],\n",
       "       [151],\n",
       "       [152],\n",
       "       [153],\n",
       "       [154],\n",
       "       [155],\n",
       "       [156],\n",
       "       [157],\n",
       "       [158],\n",
       "       [159],\n",
       "       [160],\n",
       "       [161],\n",
       "       [162],\n",
       "       [163],\n",
       "       [164],\n",
       "       [165],\n",
       "       [166],\n",
       "       [167],\n",
       "       [168],\n",
       "       [169],\n",
       "       [170],\n",
       "       [171],\n",
       "       [  4],\n",
       "       [172],\n",
       "       [173],\n",
       "       [174],\n",
       "       [175],\n",
       "       [176],\n",
       "       [177],\n",
       "       [178],\n",
       "       [179],\n",
       "       [180],\n",
       "       [181],\n",
       "       [182],\n",
       "       [  5],\n",
       "       [183],\n",
       "       [184],\n",
       "       [185],\n",
       "       [186],\n",
       "       [187],\n",
       "       [188],\n",
       "       [189],\n",
       "       [190],\n",
       "       [191],\n",
       "       [192],\n",
       "       [193],\n",
       "       [194],\n",
       "       [195],\n",
       "       [196],\n",
       "       [197],\n",
       "       [198],\n",
       "       [199],\n",
       "       [200],\n",
       "       [201],\n",
       "       [202],\n",
       "       [203],\n",
       "       [204],\n",
       "       [205],\n",
       "       [206],\n",
       "       [207],\n",
       "       [208],\n",
       "       [209],\n",
       "       [210]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(193, 1)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(sequences_padded, words_label_encoded_np, test_size=0.1, random_state=50)\n",
    "\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(193, 1)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 1)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not os.path.exists('classifier.keras'):\n",
    "    model = Sequential()\n",
    "    model.add(layers.Embedding(193, 16))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('classifier.keras'):\n",
    "    model = load_model('classifier.keras', compile=False)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.9784 - loss: 0.6299 - val_accuracy: 0.5000 - val_loss: 0.6953\n",
      "Epoch 2/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9685 - loss: 0.6272 - val_accuracy: 0.5000 - val_loss: 0.6949\n",
      "Epoch 3/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9709 - loss: 0.6178 - val_accuracy: 0.4545 - val_loss: 0.6947\n",
      "Epoch 4/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9737 - loss: 0.6114 - val_accuracy: 0.4545 - val_loss: 0.6947\n",
      "Epoch 5/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9688 - loss: 0.6036 - val_accuracy: 0.4091 - val_loss: 0.6946\n",
      "Epoch 6/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9680 - loss: 0.5976 - val_accuracy: 0.4091 - val_loss: 0.6944\n",
      "Epoch 7/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9751 - loss: 0.5861 - val_accuracy: 0.4091 - val_loss: 0.6943\n",
      "Epoch 8/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9628 - loss: 0.5821 - val_accuracy: 0.4091 - val_loss: 0.6943\n",
      "Epoch 9/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9719 - loss: 0.5708 - val_accuracy: 0.4091 - val_loss: 0.6949\n",
      "Epoch 10/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9703 - loss: 0.5649 - val_accuracy: 0.4091 - val_loss: 0.6950\n",
      "Epoch 11/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9446 - loss: 0.5619 - val_accuracy: 0.4091 - val_loss: 0.6948\n",
      "Epoch 12/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9543 - loss: 0.5532 - val_accuracy: 0.4091 - val_loss: 0.6945\n",
      "Epoch 13/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9777 - loss: 0.5317 - val_accuracy: 0.4091 - val_loss: 0.6943\n",
      "Epoch 14/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9764 - loss: 0.5263 - val_accuracy: 0.4091 - val_loss: 0.6942\n",
      "Epoch 15/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9644 - loss: 0.5190 - val_accuracy: 0.4091 - val_loss: 0.6939\n",
      "Epoch 16/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9752 - loss: 0.5085 - val_accuracy: 0.4091 - val_loss: 0.6938\n",
      "Epoch 17/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9752 - loss: 0.4981 - val_accuracy: 0.4091 - val_loss: 0.6946\n",
      "Epoch 18/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9599 - loss: 0.4978 - val_accuracy: 0.4091 - val_loss: 0.6947\n",
      "Epoch 19/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9678 - loss: 0.4798 - val_accuracy: 0.4091 - val_loss: 0.6947\n",
      "Epoch 20/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9644 - loss: 0.4749 - val_accuracy: 0.4091 - val_loss: 0.6947\n",
      "Epoch 21/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9657 - loss: 0.4624 - val_accuracy: 0.4091 - val_loss: 0.6956\n",
      "Epoch 22/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9655 - loss: 0.4529 - val_accuracy: 0.4091 - val_loss: 0.6958\n",
      "Epoch 23/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9685 - loss: 0.4424 - val_accuracy: 0.4091 - val_loss: 0.6955\n",
      "Epoch 24/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9707 - loss: 0.4299 - val_accuracy: 0.4091 - val_loss: 0.6951\n",
      "Epoch 25/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9823 - loss: 0.4162 - val_accuracy: 0.4091 - val_loss: 0.6950\n",
      "Epoch 26/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9616 - loss: 0.4189 - val_accuracy: 0.4091 - val_loss: 0.6945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x17a6219a4b0>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "model.fit(x_train, y_train, epochs=200, validation_data=(x_test, y_test), callbacks=early_stopping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('classifier.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9812 - loss: 0.3960 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4012526571750641, 0.9689119458198547]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = model.evaluate(x_train, y_train)\n",
    "loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
